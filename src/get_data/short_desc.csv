"YETUS-220" "The copy code doesn t know about the version file and the code that reads it expects it to appear outside of where the copy code would normally put it " " This might be fixed in the tar ball release but we should still make it work from a source checkout "
"FLINK-1206" "null" "null"
"CASSANDRA-11915" "This patch just corrected the section number opcode detail is described in Section " " Committed as f f ce fe acec c b d ee cb to and merged with an trunk thanks "
"XERCESJ-874" "The error reported is Error on line of document http www w org TR voicexml synthesis core xsd InvalidRegex Pattern value is not a valid regular expression The reported error was is an invalid character range Write I guess this is thrown from the first character group and this goes against that quote in the XML Schema Part W C Recommendation dated May quote The character is a valid character range only at the beginning or end of a positive character group quote " " This line was removed by the erratum E the rationale being that this line contradicts production therefore this pattern is actually invalid This problem appears to have been fixed in the schema for VoiceXML currently at http www w org TR voicexml synthesis core xsd http www w org xmlschema errata E "
"CASSANDRA-10897" "In AbstractBTreePartition toString which PartitionUpdate extends we iterate over the rows in the partition This triggers maybeBuild in the PartitionUpdate If the PartitionUpdate gets updated after the toString call it will result in an IllegalStateException with the message An update should not be written again once it has been read " " Patch and pending CI runs branch testall dtest CASSANDRA testall dtest CASSANDRA trunk testall dtest "
"SHINDIG-968" "In java gadgets src test java org apache shindig gadgets GadgetFeatureRegistryTest java line you see the following code List String deps Lists newLinkedList if deps null " " Small patch "
"ODE-1030" "WAR JBI distributions of have JARs in their lib directory that don t contain Java class files Instead there are files with html extension Because auf that when testing the examples sendsoap fails with a ClassNotFoundException i e the instructions in section Examples of WAR deployment don t work with the release Version on the other hand works as expected " " Thanks for reporting Is this a dupe of ODE "
"FLUME-2592" "flume tools is missing main manifest attribute which causes the failure to launch flume tools Running it results in following errorbash java jar flume tools SNAPSHOT jar h no main manifest attribute in flume tools SNAPSHOT jarThe help option printed also misses the jar to be used usage java jar fcintegritytool h l arg h help Display help l dataDirs arg Comma separated list of data directories which the tool must verify This option is mandatory" " Looked at the code tool can be run from flume ng script The help message needs to be fixed Options are either we point it to use the flume ng script or can leave it to run as standalone file by modifying pom xml painful with classpath settings and all Hari Shreedharan Roshan Naik Suggestions on fixing this "
"SM-1295" "When using BinaryFileMarshaler with FtpPoller File not found excelption It seems to be looking for the file on the local server rather than ftp location java io FileNotFoundException dnbusr ks control Input txt The system cannot find the path specified at java io FileInputStream open Native Method at java io FileInputStream init FileInputStream java at javax activation FileDataSource getInputStream FileDataSource java at javax activation DataHandler getInputStream DataHandler java Code responsible for the problem are the following lines in BinaryFileMarshaler public void readMessage MessageExchange exchange NormalizedMessage message InputStream in String path throws IOException JBIException " " Lars explicitely changed that a few weeks ago http fisheye cenqua com browse servicemix smx trunk core servicemix core src main java org apache servicemix components util BinaryFileMarshaler java r r I don t recall exactly what was the probem Lars "
"IVY-441" "If you intend to publish an artifact on or more configurations and you use the character as configurations separator in conf attribute of publications artifact element ivy simply continues and publish nothing but ivy xml No jars are published The correct separator is character so separator should cause ivy to fail or at least warn Example not working ivy xml published only ivy xml ivy module version info organisation ivy bug module test proj revision configurations conf name compile transitive false conf name runtime configurations publications artifact name test proj type jar conf compile runtime publications ivy module Working ivy xml publishes also jar ivy module version info organisation ivy bug module test proj revision configurations conf name compile transitive false conf name runtime configurations publications artifact name test proj type jar conf compile runtime publications ivy module " " This should be fixed in SVN "
"CAMEL-9166" "Changes in Camel cause properties prefixing to not work for Camel context ID See notes in https github com apache camel commit aa cec c d f ae bd fabbaa Also backward compatibility to is removed See note in https github com apache camel commit c b e ae da ca e e acc fd ae " " GitHub user yuruki opened a pull request https github com apache camel pull CAMEL Some functionality broken in Camel https issues apache org jira browse CAMEL You can merge this pull request into a Git repository by running git pull https github com yuruki camel camel scr test Alternatively you can review and apply these changes as the patch at https github com apache camel pull patch To close this pull request make a commit to your master trunk branch with at least the following in the commit message This closes commit fcb ebbdb cc ed c f c d f c Author Jyrki Ruuskanen yuruki kotikone fi Date T Z Camel "
"LUCENE-4269" "http job Lucene trunk Linux Java was hung for a couple days stacktrace " " Events file BOOTSTRAP defaultCharset US ASCII systemProperties awt toolkit sun awt X XToolkit file encoding US ASCII file encoding pkg sun io file separator java awt graphicsenv sun awt X GraphicsEnvironment java awt printerjob sun print PSPrinterJob java class path var lib jenkins workspace Lucene trunk Linux Java checkout lucene build test framework classes java var lib jenkins workspace Lucene trunk Linux Java checkout lucene build core classes java var lib jenkins workspace Lucene trunk Linux Java checkout lucene test framework lib junit jar var lib jenkins workspace Lucene trunk Linux Java checkout lucene test framework lib randomizedtesting runner jar var lib jenkins workspace Lucene trunk Linux Java checkout lucene build misc classes java var lib jenkins workspace Lucene trunk Linux Java checkout lucene build misc classes test var lib jenkins tools ant supported lib ant launcher jar var lib jenkins ant lib apache rat tasks jar var lib jenkins ant lib ivy jar var lib jenkins ant lib apache rat jar var lib jenkins ant lib apache rat plugin jar var lib jenkins ant lib apache rat core jar var lib jenkins ant lib clover jar var lib jenkins tools ant supported lib ant apache regexp jar var lib jenkins tools ant supported lib ivy jar var lib jenkins tools ant supported lib ant jmf jar var lib jenkins tools ant supported lib ant apache log j jar var lib jenkins tools ant supported lib ant jdepend jar var lib jenkins tools ant supported lib ant swing jar var lib jenkins tools ant supported lib ant antlr jar var lib jenkins tools ant supported lib ant apache xalan jar var lib jenkins tools ant supported lib ant apache resolver jar var lib jenkins tools ant supported lib ant commons logging jar var lib jenkins tools ant supported lib ant testutil jar var lib jenkins tools ant supported lib ant apache bcel jar var lib jenkins tools ant supported lib ant jsch jar var lib jenkins tools ant supported lib ant junit jar var lib jenkins tools ant supported lib ant commons net"
"ACCUMULO-2213" "During a hour continuous ingest test with agitation the following was reported k times " " I can make this happen reliably on while using gremlins to disrupt the node the tracer is on I also get exceptions in the main loop which blows up the log for the service trace TraceServer ERROR Unable to write mutation to table org apache accumulo core data Mutation java lang IllegalStateException Closed at org apache accumulo core client impl TabletServerBatchWriter addMutation TabletServerBatchWriter java at org apache accumulo core client impl BatchWriterImpl addMutation BatchWriterImpl java at org apache accumulo server trace TraceServer Receiver span TraceServer java at org apache accumulo cloudtrace thrift SpanReceiver Processor span process SpanReceiver java at org apache accumulo cloudtrace thrift SpanReceiver Processor process SpanReceiver java at org apache thrift server TThreadPoolServer WorkerProcess run TThreadPoolServer java at java util concurrent ThreadPoolExecutor Worker runTask ThreadPoolExecutor java at java util concurrent ThreadPoolExecutor Worker run ThreadPoolExecutor java at java lang Thread run Thread java trace TraceServer ERROR Unable to write mutation to table org apache accumulo core data Mutation java lang IllegalStateException Closed at org apache accumulo core client impl TabletServerBatchWriter addMutation TabletServerBatchWriter java at org apache accumulo core client impl BatchWriterImpl addMutation BatchWriterImpl java at org apache accumulo server trace TraceServer Receiver span TraceServer java at org apache accumulo cloudtrace thrift SpanReceiver Processor span process SpanReceiver java at org apache accumulo cloudtrace thrift SpanReceiver Processor process SpanReceiver java at org apache thrift server TThreadPoolServer WorkerProcess run TThreadPoolServer java at java util concurrent ThreadPoolExecutor Worker runTask ThreadPoolExecutor java at java util concurrent ThreadPoolExecutor Worker run ThreadPoolExecutor java at java lang Thread run Thread java I think there are two issues here that the writer gets closed and that our"
"XERCESJ-449" "When compiling the org apache xerces impl validation package files especially during org apache xerces impl validation ValidationState java it throws an exception saying ClassNotFoundException org apache xerces impl dv ValidationContext java The documentation shows that ValidationContext java is in org apache xerces impl validation package but Source code of org apache xerces impl validation ValidationState java uses org apache xerces impl dv ValidationContext java and ValidationContext java file is in org apache xerces impl validation package I am confused If any of you could help me it will be great " " It sounds like you re trying to compile only the classes within one package which in general may not be possible because they may depend on other classes which haven t been compiled yet Trying to hand compile Xerces is tricky as we do a number of things replacing text copying files to other locations excluding source files etc in the Ant build script If you want to compile the source code I suggest you have a look at http xml apache org xerces j faq build html If you have further problems with compilation could you please address them to the xerces j user list http xml apache org mail html xerces j user "
"WICKET-4553" "I replicated the example in https cwiki apache org WICKET how to load an external image html and I noticed that the generated URL when using ResourceReference imageResource new SharedResourceReference documentResource String url RequestCycle get urlFor imageResource new PageParameters id on a bookmarkable page causes a java lang ClassNotFoundException resource Generated URL resource org apache wicket Application documentResource id added to a bookmarkable page http localhost app wicket bookmarkable resource org apache wicket Application documentResource id on a non bookmarkable page " " Can you attach a quickstart application please "
"OOZIE-2155" "We discovered a critical bug where incorrect Daylight Saving Time shifts were occurring based on the Database timezone Try running this Coordinator Note that it runs over a DST shift at least in most US timezones Here s a sample of some of the actions along with their Nominal Times Note that actions and have the same time This is incorrect because the times are in GMT with no DST I ve also confirmed via a debugger that these dates have the same number of seconds since epoch so it s not just a rendering issue By the way if you re in a different timezone you ll see this problem occur on different actions because the issue is related to the timezone that your database is in It depends on when the DST shift occurs in your timezone for example in America New York it happens with actions and On that note if I ask Oozie to use America Los Angeles to print the dates I get this Action s nominal time should be PDT not PST Using the debugger some more I verified that Oozie is creating the nominal times correctly and writing them to the database correctly at least it s converting them to Java s SQL TimeStamp objects correctly OpenJPA handles writing them But when the problematic value is read back from the database it has the wrong value Here s something interesting from the MySQL documentation MySQL converts TIMESTAMP values from the current time zone to UTC for storage and back from UTC to the current time zone for retrieval This does not occur for other types such as DATETIME By default the current time zone for each connection is the server s time The time zone can be set on a per connection basis As long as the time zone setting remains constant you get back the same value you store If you store a TIMESTAMP value and then change the time zone and retrieve the value the retrieved value is different from the value you stored This occurs because the same time zone was not used for conversion in both directions So I think what s happening is that it s interpreting everything i" " We were able to test this on Oracle and it is also affected by this issue but we couldn t figure out how to set the timezone over JDBC I found a Stack Overflow comment describing how we could call a proprietary OracleConnection setSessionTimeZone method using reflection to do this but I haven t tried it "
"QPID-6560" "On intruder detection a task to close VHN children and set VHN state to ERRORED is scheduled in Broker configuration thread Immediately after scheduling the task ReplicatedEnvironmentFacade close is invoked ReplicatedEnvironmentFacade executors are shutdown in close method If any of ReplicatedEnvironmentFacade executors has a pending work tasks to run and that work needs to be performed in VHN configuration thread or Broker configuration thread in synchronous manner blocking ReplicatedEnvironmentFacade executors threads the executors shutdown would be blocked and eventually times out Test BDBHAVirtualHostNodeRestTest testIntruderProtection fails sporadically as indicated by stack trace below The log analysis showed that the issue occurs in the following scenario " " Commit from orudyy apache org in branch java trunk https svn apache org r QPID Remove redundant close of ReplicationEnvironmentFacade on intruder detection as it might block on facade thread executors shutdown caused by tasks scheduled to execute on VHN close and HA events "
"ACCUMULO-3408" "This is a regression of ACCUMULO " " Getting null pointer and class cast exceptions "
"AXIS2-4853" "When trying to use axis osgi with the upstream axiom version the following error appears org osgi framework BundleException Activator start error in bundle org apache axis osgi at org apache felix framework Felix activateBundle Felix java at org apache felix framework Felix startBundle Felix java at org apache felix framework BundleImpl start BundleImpl java at org apache felix framework BundleImpl start BundleImpl java at com profitbricks osgi test FelixTest deployBundle FelixTest java at com profitbricks osgi test FelixTest testModules FelixTest java Caused by org apache axiom om OMException java lang ClassNotFoundException org apache axiom om impl llom factory OMLinkedListMetaFactory at org apache axiom om OMAbstractFactory getMetaFactory OMAbstractFactory java at org apache axiom om OMAbstractFactory getOMFactory OMAbstractFactory java at org apache axis description AxisDescription init AxisDescription java at org apache axis engine AxisConfiguration init AxisConfiguration java at org apache axis osgi deployment OSGiServerConfigurator populateAxisConfiguration OSGiServerConfigurator java at org apache axis osgi deployment OSGiServerConfigurator getAxisConfiguration OSGiServerConfigurator java at org apache axis context ConfigurationContextFactory createConfigurationContext ConfigurationContextFactory java at org apache axis osgi deployment OSGiConfigurationContextFactory startConfigurationContext OSGiConfigurationContextFactory java at org apache axis osgi deployment OSGiConfigurationContextFactory updated OSGiConfigurationContextFactory java at org apache axis osgi internal Activator start Activator java at org apache felix framework util SecureAction startActivator SecureAction java at org apache felix framework Felix activateBundle Felix java more Caused by java lang ClassNotFoundException org apache axiom om impl llom factory OMLinkedListMetaFactory at org apache felix framework ModuleImpl findClassOrResourceByDelegation ModuleImpl java at org apache felix f" " Can you explain the steps to reproduce the issue Is it enough to install the Axis and Axiom bundles into an OSGi container and attempt to start them or are there any other things that are necessary to trigger the error "
"CAMEL-7968" "The implementation of Container Instance is not ThreadSafe It is also not defined what happens when multiple Containers race on the singleton " " Added more details in the javadoc that Container is not thread safe which has never been the intention either "
"AMQ-5165" "Destination statistics queue name is documented asActiveMQ Statistics Destination DEST NAME but it is really implemented asActiveMQ Statistics Destination DEST NAME " " Fixed with http git wip us apache org repos asf activemq commit eb f "
"WICKET-6040" "After upgrading to I encountered NotSerializableException when refreshing DebugBar in an ajax event Martin Grigorov suspects this is related to https github com apache wicket commit d ccdd f f ca f b a ee b a To reproduce this start the application in development mode override onEvent in Application to refresh the DebugBar public void onEvent IEvent event if event getPayload instanceof AjaxRequestTarget AjaxRequestTarget target AjaxRequestTarget event getPayload if we are in development refresh the debugbar if exists if getConfigurationType RuntimeConfigurationType DEVELOPMENT From stacktrace it seems this is related to org apache wicket ajax AbstractAjaxResponse AjaxHtmlHeaderContainer " " Commit a eabcc a bd b ea b abceb dee in wicket s branch refs heads wicket x from Sven Meier https git wip us apache org repos asf p wicket git h a eab WICKET restore AjaxHtmlHeaderContainer to be static so it can be serialized before AjaxRequest has finished "
"XERCESJ-512" "bug java import javax xml parsers import org w c dom class bug public static void main String args throws Exception bug xml xml version encoding UTF DOCTYPE bug ELEMENT bug itemlist ELEMENT itemlist item a item b item c item b ELEMENT item a EMPTY ELEMENT item b EMPTY ELEMENT item c EMPTY ATTLIST itemlist value CDATA REQUIRED ATTLIST item a value CDATA REQUIRED ATTLIST item b value REQUIRED ATTLIST item c value CDATA REQUIRED bug itemlist value item a value URL item b value itemlist itemlist value item a value URL item b value itemlist itemlist value item a value URL item c value check itemlist itemlist value item a value URL item c value check item b value itemlist itemlist value item a value URL item c value check item b value itemlist bug " " ELEMENT itemlist item a item b item c item b This content model is illegal and the error message is correct You cannot mix sequence and choice operators at the same level of the content model "
"AXIS2-4381" "The service name used in the generated Service stubs are not unique when using wsdl java Maven plugin The names are built from the unqualified service name concatenated with a suffix from the following method private static synchronized String getUniqueSuffix reset the counter if it is greater than if counter counter counter return Long toString System currentTimeMillis counter The problem is that each service stub has its own version of this unique suffix method and thus two or more methods could be called concurrently and thus generate the same suffix If the classes they belong to have the same unqualified name the service names will be identical and thus the last one to be created will fail when it is beeing registered in the AxisConfiguration Solutions " " this is a static synchronize method so it should not have the problem you have mentioned "
"HIVE-15065" "Currently the decision to use fetch optimizer or not is based on scanning the filesystem for file lengths and see if the aggregated size is less the fetch task threshold This can be very expensive for cloud environment This issue is mitigated to some extent by HIVE but still that requires file system scan We can make decision based on the stats from metastore and falling back when stats is not available Since fast stats numRows and fileSize is always available this should work most of the time " " Ashutosh Chauhan can you please review "
"CASSANDRA-11867" "NIODataInputStream allocates direct memory but does not clean it on close Proposed patch adds a call to FileUtils clean for this direct memory buffer " " Added call to FileUtils clean to NIODataInputStream close Branch for differs from But merges cleanly up to trunk branch testall dtest branch testall dtest branch testall dtest branch testall dtest "
"COMPRESS-158" "When zipping a directory that contains several files and subdirectories of which some can be empty I am missing empty directories When using a tar archive format empty directories are present " " CompressionUtil Code used to produce the problem test zip contains a directory that when ziped using the code from CompressionUtil exhibits the problem of the empty directory disappearing "
"HAMA-973" "Today I tested fault tolerance function with RandBench FT works fine but I just found that there is a bug in RandBench program I ran with set the max iteration to At superstep I killed one task manually and I checked that failed task has automatically recovered By the way the total num of supersteps was not The reason is simple i always starts from To fix this issue we have to set the i to int peer getSuperstepCount " " root cluster hama trunk bin hama jar examples target hama examples SNAPSHOT jar bench WARN util NativeCodeLoader Unable to load native hadoop library for your platform using builtin java classes where applicable INFO Configuration deprecation user name is deprecated Instead use mapreduce job user name INFO bsp BSPJobClient Running job job INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient Current supersteps number INFO bsp BSPJobClient The total number of supersteps INFO bsp BSPJobClient Counters INFO bsp BSPJobClient org apache hama bsp JobInProgress JobCounter INFO bsp BSPJobClient SUPERSTEPS INFO bsp BSPJobClient LAUNCHED TASKS INFO bsp BSPJobClient org apache hama bsp BSPPeerImpl PeerCounter INFO bsp BSPJobClient SUPERSTEP SUM INFO bsp BSPJobClient TIME IN SYNC MS INFO bsp BSPJobClient TOTAL MESSAGES SENT INFO bsp BSPJobClient TOTAL MESSAGES RECEIVED Job Finished in seconds Good it works as I expected By the way FT doesn t works occasionally I ll look more "
"TAP5-2462" "Calling Grid reset from the parent component may result in NullPointerException Caused by java lang NullPointerException at org apache tapestry corelib components Grid setCurrentPage Grid java at org apache tapestry corelib components Grid reset Grid java at org tynamo examples simple pages List resetGrid List java at org tynamo examples simple pages List setupRender List java " " Commit bc fab b d a d a b bfd b b in tapestry s branch refs heads master from kaosko https git wip us apache org repos asf p tapestry git h bc fab FIXED TAP Parent component should be able to reset a Grid regardless of its internal state do sortModel clear before setting the current page because the formerl internally calls the private operation setupPaginationModel otherwise you may get a null pointer "
"SYNAPSE-903" "Let s assume we have a proxy service that has DBLookup mediator configured to use a globally defined datasources in one of its sequences There if we hot update the service like you mentioned the existing service is stopped and all the mediator life cycles configured would also be destroyed When the AbstractDBMediator s destroy method gets invoked it closes the associated datasource without considering the fact that it is configured globally Therefore the subsequent invocations fail as the datasource has already been closed" " Attaching the patch to fix the issue Please review and apply Regards Prabath "
"CASSANDRA-10749" "org apache cassandra db DeletionTime compareTo looks like this " " That definitively is an oversight care to provide a patch I ll note that this is actually pretty old dating back from the patch for CASSANDRA Also this is pretty much innocuous if DeletionTime have the same markedForDeleteAt their localDeletionTime will likely be the same and if not will be very close and we don t really care all that much how we sort them We should still fix it of course "
"PHOENIX-3416" "when executing EXPLAIN query hive doesn t execute Tasks that get and remove PhoenixPredicateDecomposer from PREDICATE DECOMPOSER MAP so all predicate decomposers made from the explain query exists forever in the decomposer map " " removed PhoenixPredicateDecomposerManager and PhoenixPredicateDecomposer decompose predicate again in inputformat to get search conditions "
"KNOX-149" "remove plural from servicename acls remove processing from servicename acl processing mode make default mode AND top level config for mode" " Commit bd dd bd b d c f d f in branch refs heads master from Larry McCay https git wip us apache org repos asf p incubator knox git h bd KNOX addressed config changes and default processing mode "
"JS1-450" "We have added sorting to several Admin portlets such as UserRoleUpdateAction Is this the correct place to submit an enhancement Is there a way to upload the entire class or should we just paste in the changed code This is from the procedure buildUserRoleContext while roles hasNext masterRoles trimToSize Now sort the roles here Collections sort masterRoles new Comparator public int compare Object o Object o roles masterRoles iterator If I m off base here would someone kindly let me know " " Please add a patch file with your changes to this bug for review "
"CTAKES-218" "The error was seen HyphenTextModifierImpl which is not that important anymore but the underlying issue is that the try clause within org apache ctakes core resource FileLocator assumes FileLocator class getClassLoader getResourceAsStream location will throw an Exception if something goes wrong but it doesn t always it can just return null in which case the catch clause is not running" " Commit from james masanz apache org in branch ctakes trunk https svn apache org r CTAKES Have FileLocator also try the second method to resolve the file path if the first returns null in addition to if the first throws an exception "
"SHINDIG-1635" "I m using google s gwt gadgets library in gadget development Generated javascript may contain construction like this When this javascript is going thru proxy it gets brokenThe script is served as text javascript content type " " Igor is this only a problem in the PHP version of Shindig "
"OOZIE-2090" "Suppose you have a workflow where an action fails on the first try but the automatic retry behavior for transient failures kicks in and it succeeds on one of the later tries Currently the wf lastErrorNode EL Function will show that this node failed even though it ultimately succeeded " " The way wf lastErrorNode works is that DagELFunctions setActionInfo checks if the action s status is ERROR and sets a variable to the node s name The problem is that ActionEndXCommand temporarily changes the action s status to ERROR in this case it gets set back to END RETRY if there s a retry but the DagELFunctions setActionInfo call happens first so it thinks the action failed always The patch simply moves the call to later in ActionEndXCommand so that the action s status can stabilize before setting or not setting it as the last error node "
"ACCUMULO-3709" "If mutations are rejected during the close of the output formatter and subsequently the writer which causes a flush then the exception is not rethrown only logged " " Good catch marco polo It looks like this has been around for ages If you can basing your patch might be best to make sure we squash this bug everywhere didn t forcibly change that on you since I don t want it to seem like I m forcing you to give me a patch there any patch is great "
"CB-11199" "FileReader readAsDataURL method encodes invalid base data for a jpeg image I could not decode the generate base data But iI tried the same situation on version it works successfully " " Can you share a snippet of code that you are using "
"AXIS2-5754" "I configured my axis wsdl code maven plugin like sothe result is that the plugin is generating sources that do not compile For example " " here are the wsdl with the xsd files "
"DIRMINA-1045" "The setAll IoSessionConfig method does not set all the possible configurtion parameters typically the specific ones for each AbstratIsSessionConfig subclasses aren t supported KeepAlive for the AbstractSocketSessionConfig class etc This is because teh setAll method is declared as final in the AbstractIoSessionConfig and can t be overloaded " " Actually and I have missed it there is a call to a doSetAll method in the setAll method that will let the inherited class to update the configuration including the specific parameters Regardless I think that it would be way simpler to override the setAll methods in each implementation calling the parent s setAll method like in AbstractSocketSessionConfig setAll IoSessionConfig config super setAll config AbstractSocketSessionConfig cfg AbstractSocketSessionConfig config if cfg isKeepAliveChanged setKeepAlive cfg isKeepAlive This would do the same work but in a much simpler way "
"THRIFT-4060" "I m in the middle of converting a project that provides some ostream operators for logging purposes for a number of thrift structures The project was using and in some ostream operator overloads were added with THRIFT The solution that was provided here runs into complications if a thrift structure is contained within another one Take this simple example I m considering adding an annotation to the thrift IDL that the compiler will recognize that allows someone to say I am going to provide my own operator for this structure don t generate one This would replace the printTo mechanism that was added in THRIFT Here is an example " " GitHub user jeking opened a pull request https github com apache thrift pull THRIFT add better support in the cpp generator for custom ostream operators on structures This pull request adds support for an annotation that will disable the emit code for operator and printTo allowing a custom streaming output format to be provided by the consuming application You can merge this pull request into a Git repository by running git pull https github com jeking thrift THRIFT Alternatively you can review and apply these changes as the patch at https github com apache thrift pull patch To close this pull request make a commit to your master trunk branch with at least the following in the commit message This closes commit db cb a a c cf c a b a f Author James E King III jim king simplivity com Date T Z THRIFT add better support in the cpp generator for custom ostream operators on structures "
"HIVE-14680" "see HIVE Basic idea spent about minutes thinking about this based on RB comment is to return locations for all slots to HostAffinitySplitLocationProvider the missing slots being inactive locations based solely on the last slot actually present For the splits mapped to these locations fall back via different hash functions or some sort of probing " " Prasanth Jayachandran Gopal V can you take a look I need to test this in a cluster too "
"ZEPPELIN-2091" "I faced the following issue like screenshot in new window which is created by Link this paragraph Here is the test way click Link this paragraph of a original paragraph menu click Insert New check the window made in Link this paragraph " " Sora Lee While I tired to reproduce this issue recorded gif screenshot img and attatched it Hope this helps other ppl understand this issue "
"DRILL-1172" "I am running Drill on CDH I have created a Hive Storage plugin as follows I connect to sqlline as follows opt drill apache drill m incubating SNAPSHOT bin sqlline u jdbc drill schema hive zk When I run a query against a hive table it errors out as follows I have even tried setting the below property in the hive storage plugin but it still errors out fs defaultFS hdfs The exception in the drillbit log is In the incubator drill contrib storage hive core src main java org apache drill exec store hive HiveScan java class the error is occurring because the FileSystem object being created in the getSplits method is pointing to file This FileSystem object is being created from a JobConf object The contents of the JobConf object are Configuration core default xml core site xml mapred default xml mapred site xml yarn default xml yarn site xml hdfs default xml hdfs site xml" " fixed by d befc or earlier "
"FELIX-525" "jlaskowski dev cygdrive c apps felix java jar bin felix jarWelcome to Felix " " Hmmm I tried under JDK and Welcome to Felix Enter profile name heavy felix trunk main java jar bin felix jar Welcome to Felix Enter profile name heavy felix trunk main Worked ok in both cases Which platform are you using I am testing on Fedora "
"DIRSTUDIO-1080" "Using the new installed Studio and the new installed ApacheDS Server i can t save the Server Configuration with DS Studio I changed nothing in the configuration When i try to save the config i can see the following exceptions Exception shown in DS Log INFO jvm ERROR org apache directory server core schema SchemaInterceptor Exception shown in DS Studio Dialog Error Message java lang Exception at org apache directory studio apacheds configuration editor ServerConfigurationEditorUtils saveConfiguration ServerConfigurationEditorUtils java at org apache directory studio apacheds configuration jobs SaveConfigurationRunnable run SaveConfigurationRunnable java at org apache directory studio common core jobs StudioJob run StudioJob java " " It happens when opening saving the configuration via connection to the remote server "
"CTAKES-242" "Issue reported to dev see http markmail org message niqxtrexekyclxry These is a minors bugs that i have corrected it may be of use for the next release I the XCasWriterCasConsumer xml analysis engine cas consumer of ctakes core referes to org apache uima examples cpe XCasWriterCasConsumer which does not exists I found the java class XCasWriterCasConsume java from an old version of cTakes and copied in org apache ctakes core cc Changed org apache uima examples cpe XCasWriterCasConsumer by org apache ctakes core cc XCasWriterCasConsumer " " Commit from james masanz apache org in branch ctakes trunk https svn apache org r CTAKES XCasWriterCasConsumer issues added uima examples as a dependency since org apache uima examples cpe XCasWriterCasConsumer does exist there "
"AXIS2-5262" "The exception in the same as in AXIS but Im not sure if it has the same originorg apache axis AxisFault InvalidSecurity at org apache rampart handler PostDispatchVerificationHandler invoke PostDispatchVerificationHandler java at org apache axis engine Phase invoke Phase java at org apache axis engine AxisEngine invoke AxisEngine java at org apache axis engine AxisEngine receive AxisEngine java at org apache axis transport http HTTPTransportUtils processHTTPPostRequest HTTPTransportUtils java at org apache axis transport http AxisServlet doPost AxisServlet java at javax servlet http HttpServlet service HttpServlet java we do have services and we are using MTOM in the Clients to sent attachments Rampart engaged in the services xml and a policy using a custom password handler as follows module ref rampart module ref addressing wsp Policy wsu Id UTOverTransport xmlns wsu http docs oasis open org wss oasis wss wssecurity utility xsd xmlns wsp http schemas xmlsoap org ws policy wsp ExactlyOne wsp All sp TransportBinding xmlns sp http schemas xmlsoap org ws securitypolicy wsp Policy sp TransportToken wsp Policy sp HashPassword wsp Policy sp TransportToken wsp Policy sp TransportBinding sp SignedSupportingTokens xmlns sp http schemas xmlsoap org ws securitypolicy wsp Policy sp UsernameToken sp IncludeToken http schemas xmlsoap org ws securitypolicy IncludeToken AlwaysToRecipient wsp Policy sp SignedSupportingTokens ramp RampartConfig xmlns ramp http ws apache org rampart policy ramp passwordCallbackClass custom PasswordCallbackHandler ramp passwordCallbackClass ramp RampartConfig wsp All wsp ExactlyOne wsp Policy policy xml in client wsp Policy wsu Id UsernameToken xmlns wsu http docs oasis open org wss oasis wss wssecurity utility xsd xmlns wsp http schemas xmlsoap org ws policy wsp ExactlyOne wsp All sp SupportingTokens xmlns sp http docs oasis open org ws sx ws securitypolicy wsp Policy sp UsernameToken sp IncludeToken http docs oasis open org ws sx ws securitypolicy Inc" " I recently did some performance tests with Rampart trunk and noticed the same kind of issue When sending requests from multiple threads right after the startup Axis Rampart will hang If I send a single request before starting the performance test then the issue doesn t occur "
"FLINK-1690" "I got the following error on Travis I think we have to increase the timeouts for this test case to make it reliably run on Travis " " I do not think it is a timeout thing It seems the job simply hangs "
"SPARK-19564" "In KafkaOffsetReader when error occurs we abort the existing consumer and create a new consumer In our current implementation the first consumer and the second consumer would be in the same group which violates our intention of the two consumers not being in the same group The cause is that in our current implementation the first consumer is created before groupId and nextId are initialized in the constructor Then even if groupId and nextId are increased during the creation of that first consumer groupId and nextId would still be initialized to default values in the constructor " " User lw lin has created a pull request for this issue https github com apache spark pull "
"IGNITE-3273" "Distributed SQL query cannot be parsed on map side if it contains left join The same local query works without any error Replacing left join with inner join removes the error See the attachment for the reproducer " " merged to master "
"TEZ-21" "null" "null"
"CB-10809" "NPM points to version of the plugin which is an old version where callbacks don t work Version in github works fine Please update your npm link " " This is a side effect of how we chose to pin plugin versions when using cordova CLI We have removed this feature now and it will not be an issue in cordova "
"IVY-1009" "I m using Ivy in standalone mode to manage DLLs for a C project I have an SSH repository set up which works fine for retrieving artifacts but not for publishing them " " Also it doesn t hang using the same settings file via ant "
"XERCESJ-344" "hi i have one problem while building Document from XML file my xml file is somewhat like below snippet although slightly bigger xml version DocEle Node Node hello world Node Node DocEle Now the problem is n newline character which is coming after Node and before start of Node is being treated as text child node of Node i am not using DTD or schema i dont want to use DTD OR schema still i want the n characters which are not actually content to be ignored while building document as you might also agree that the n characters coming after nodenames are not text childs of that node can anybody tell me how to ignore n characters while building document using DocumentBuilder what settings or parameter setting to be done i have tried with setIgnoringElementContentWhitespace true but with no success " " This is a more general XML parsing issue that could be best answered on the xerces j dev xml apache org list or an XML FAQ site like xml org "
"IVYDE-130" "null" "null"
"PIVOT-735" "I have a textarea with scrollpane like this ScrollPane horizontalScrollBarPolicy fill verticalScrollBarPolicy fill to capacity maximumHeight preferredWidth TextArea text Lorem ipsum ScrollPane " " this is a sample of this problem "
"AXIS2-5113" "Wsdl fragment Exception java lang RuntimeException java lang reflect InvocationTargetException at org apache axis databinding utils BeanUtil getPropertyQnameList BeanUtil java at org apache axis databinding utils BeanUtil getPullParser BeanUtil java at org apache axis databinding utils reader ADBXMLStreamReaderImpl processProperties ADBXMLStreamReaderImpl java at org apache axis databinding utils reader ADBXMLStreamReaderImpl next ADBXMLStreamReaderImpl java at org apache axis databinding utils reader WrappingXMLStreamReader next WrappingXMLStreamReader java at org apache axis databinding utils reader ADBXMLStreamReaderImpl next ADBXMLStreamReaderImpl java at org apache axis util StreamWrapper next StreamWrapper java at org apache axiom om impl builder StAXOMBuilder parserNext StAXOMBuilder java at org apache axiom om impl builder StAXOMBuilder next StAXOMBuilder java at org apache axiom om impl llom OMSerializableImpl build OMSerializableImpl java at org apache axiom om impl llom OMElementImpl build OMElementImpl java at org apache axiom om impl llom OMElementImpl detach OMElementImpl java at org apache axiom om impl llom OMNodeImpl setParent OMNodeImpl java at org apache axiom om impl llom OMElementImpl addChild OMElementImpl java at org apache axiom om impl llom OMElementImpl addChild OMElementImpl java at org apache axis rpc receivers RPCUtil processResponse RPCUtil java at org apache axis rpc receivers RPCUtil processResponseAsDocLitWrapped RPCUtil java at org apache axis rpc receivers RPCMessageReceiver invokeBusinessLogic RPCMessageReceiver java at org apache axis receivers AbstractInOutMessageReceiver invokeBusinessLogic AbstractInOutMessageReceiver java at org apache axis receivers AbstractMessageReceiver receive AbstractMessageReceiver java at org apache axis engine AxisEngine receive AxisEngine java at org apache axis transport http util RESTUtil invokeAxisEngine RESTUtil java at org apache axis transport http util RESTUtil processURLRequest RESTUtil java" " Axis support java util Date IIRC xs date should be java util Date "
"DRILL-2798" "sqlline is now printing a message with the location of the log file that is breaking external scripts to extract data using Drill We need to add an option to suppress sqlline shell script messages or remove them " " DRILL patch txt don t print message about Drill log dir unless environment variable DRILL LOG DEBUG "
"GROOVY-8013" "Example shown below is for ToString but the issue affects numerous xforms " " GitHub user paulk asert opened a pull request https github com apache groovy pull GROOVY The checking of property names during AST transform attr ibute processing doesn t take into account includeSuperProperties You can merge this pull request into a Git repository by running git pull https github com paulk asert groovy groovy Alternatively you can review and apply these changes as the patch at https github com apache groovy pull patch To close this pull request make a commit to your master trunk branch with at least the following in the commit message This closes commit a fe f f a f e dab d dd ae e Author paulk paulk asert com au Date T Z GROOVY The checking of property names during AST transform attribute processing doesn t take into account includeSuperProperties "
"FLINK-2422" "A user reported via the Flink IRC channel that Firefox was showing only a blank page instead of the web client We should add a link to that page as well so that users can click it if the redirect doesn t work " " GitHub user buzdin opened a pull request https github com apache flink pull FLINK web client adding redirect link added explicit link in case browser is not redirecting properly You can merge this pull request into a Git repository by running git pull https github com buzdin flink master Alternatively you can review and apply these changes as the patch at https github com apache flink pull patch To close this pull request make a commit to your master trunk branch with at least the following in the commit message This closes commit d c a ee af c a ca c Author buzdin buzdin gmail com Date T Z FLINK web client adding redirect link added explicit link in case browser is not redirecting properly "
"FALCON-1787" "I have a Pig script that I am using as the workflow for my Falcon process The pig script uses HCatalogStorer to write to a HCatalog URI that is the output feed defined in my Falcon Process Entity The Pig action in the resulting Ooozie Workflow generated by Falcon fails with the attached stack trace The root is that it is missing a class definitions of org apache hadoop hive shims ShimLoader Running the script manually using pig x tex useHCatalog all the params passed by Oozie path to pig script results in a successful execution It s only once this is called as a Pig activity in the Falcon generated Oozie workflow that the missing class definitions manifests After some investigation I found that the Oozie workflow xml is missing a required sharelib decleration From the workflow xml generated by Falcon property name oozie action sharelib for pig name value pig hcatalog value property If I modify the value to include hive sharelib then the Pig action succeeds and does not throw a missing class definition error " " Attaching stack trace of the Pig action Falcon generated Job configuration falcon generated workflow action configuration "
"XERCESJ-1438" " fractionDigits should not be a valid facet for precisionDecimal ExampleXSD xml version schema xmlns http www w org XMLSchema targetNamespace http www schemaTest org schema xmlns si http www schemaTest org schema simpleType name decDigits restriction base precisionDecimal fractionDigits value restriction simpleType element name root complexType sequence element name elDigits type si decDigits sequence complexType element schema XML xml version encoding UTF insi root xmlns insi http www schemaTest org schema xmlns xsi http www w org XMLSchema instance xsi schemaLocation http www schemaTest org schema test fractiondigits xsd elDigits elDigits insi root Suggestion " " Fix checked in "
"CAMEL-10184" "The NettyProducer does not check if a valid ChannelGroup is declared in the NettyConfiguration and always instanciate a DefaultChannelGroup It would be interesting to add this check as done in NettyConsumer " " Are you working on a patch for this Contributions are welcome "
"STORM-402" "I have started using storm with apache tika for text extraction and I encountered a FileNotFoundException emanating from the download storm code method in supervisor clj when running in local mode I am able to submit to a remote cluster that I created Thread INFO backtype storm daemon supervisor Downloading code for storm id LocalTopology from tmp de a bb c b e d da nimbus stormdist LocalTopology Thread INFO backtype storm daemon supervisor Copying resources at jar file home milad m repository edu ucar netcdf min netcdf min jar resources to tmp a c f f d bb f e fd supervisor stormdist LocalTopology resources Thread ERROR backtype storm event Error when processing event java io FileNotFoundException Source file home milad m repository edu ucar netcdf min netcdf min jar resources does not exist at org apache commons io FileUtils copyDirectory FileUtils java commons io jar at org apache commons io FileUtils copyDirectory FileUtils java commons io jar at org apache commons io FileUtils copyDirectory FileUtils java commons io jar at backtype storm daemon supervisor fn invoke supervisor clj storm core incubating SNAPSHOT jar incubating SNAPSHOT at clojure lang MultiFn invoke MultiFn java clojure jar na at backtype storm daemon supervisor mk synchronize supervisor this invoke supervisor clj storm core incubating SNAPSHOT jar incubating SNAPSHOT at backtype storm event event manager fn invoke event clj storm core incubating SNAPSHOT jar incubating SNAPSHOT at clojure lang AFn run AFn java clojure jar na at java lang Thread run Thread java na Thread INFO backtype storm util Halting process Error when processing an event In this case the download storm code method in supervisor clj is trying to load resources from the URL jar file home milad m repository edu ucar netcdf min netcdf min jar resourcesThe relevant code in download storm code seems to be log message Copying resources at str url to target dir FileUtils copyDirectory File getFile url File target dir Since the url is" " GitHub user icksa opened a pull request https github com apache incubator storm pull Fix for STORM FileNotFoundException when using storm with apache tika This is a fix for STORM FileNotFoundException when using storm with apache tika https issues apache org jira browse STORM You can merge this pull request into a Git repository by running git pull https github com icksa incubator storm master Alternatively you can review and apply these changes as the patch at https github com apache incubator storm pull patch To close this pull request make a commit to your master trunk branch with at least the following in the commit message This closes commit c bafefdc bcefe db c d ff f Author Milad icksa gmail com Date T Z Added a hacky workaround for a FileNotFoundException I encountered while using storm and tika commit f eff b fbc b e e dfea f b d Author Milad icksa gmail com Date T Z Modified resource extraction to use getProtocol "
"LUCENE-6555" "http build eu elastic co job lucene linux java test only " " Thanks for reporting the bug but it s a dup of LUCENE I ll commit my pending patch there tomorrow morning if there are no further comments "
"WICKET-4463" "I don t know if this is actually an issue just wanted to know let you know what the recent http apache wicket n nabble com Log a warning when there are several ajax event behaviors on the same event td html change impacted We are now seeing WARN org apache wicket ajax AjaxEventBehavior org apache wicket ajax markup html AjaxLink assigned to Component id delete is overriding the previous value of the inline attribute Maybe there are several Ajax event behaviors on the same type assigned to this component Because we have an AjaxLink with added ConfirmBehavior that does not replace but enhances by appending to a behaviour ConfirmBehavior extends Behavior Override public void onComponentTag Component component ComponentTag tag StringBuilder handler new StringBuilder handler append if confirm handler append message getObject handler append String script tag getAttributes getString onclick if script null tag put onclick handler toString we can should probably change it to an AjaxCallDecorator just wanted to let others know what the change http apache wicket n nabble com Log a warning when there are several ajax event behaviors on the same event td html might affect " " Hi Serban I think you actually benefit from this warning I guess your code looks like AjaxLink l new AjaxLink l add new ConfirmBehavior parent add link If this is the case then ConfirmBehavior is added before AjaxEventBehavior because the latter is added in AjaxLink onInitialize So tag getAttributes getString onclick should always return null for you no AjaxEventBehavior onComponentTag logs this warning only if there is some value already for the event it manipulates Because it completely ignores the old value and replaces with the result of org apache wicket ajax AjaxEventBehavior getEventHandler "
"AMBARI-20273" "Steps to reproduce " " passing s pending "
"OOZIE-1818" "We need new condition to verify current time " " I actually don t see any differences except for the error message "
"REEF-1218" "IFileSystem can be implemented outside of REEF In that case when implementing FileStatus GetFileStatus FileStatus constructor might need to be called from outside of REEF Therefore it has to be public instead of internal " " Resolved via https github com apache reef pull "
"WHIRR-271" "I tried to start whirr after I had my machine split into two drives and the new location has a Macintosh HD in the name i e containing a whitespace This broke the start like so" " Trivial patch I ve tested this by running Whirr from a folder that contains a space "
"CMIS-71" "None of query parameters but the statement one are taken into account" " Applied thanks for the patch r In the same patch I also updated the SPI for query and all other methods taking an includeRelationships to change its type to conform to the spec "
"WICKET-6011" "NPE due to broken serialization happens in case DebugBar is being added to AjaxRequestTarget" " Commit a ae d e a b c f fc b e in wicket s branch refs heads wicket x from Sven Meier https git wip us apache org repos asf p wicket git h a ae d WICKET keep pageUpdate transient since the page might get serialized before the Ajax update has finished e g from Debugbar "
"ZEPPELIN-146" "In Microsoft internal deployment compatible level of IE will be set to for interant sites due to group policy set by admin Then some JavaScript will be broken and home page of Zeppelin cannot be rendered We need to set X UA Compatible tag for IE to edge to force it use the latest IE version " " GitHub user twilightgod opened a pull request https github com apache incubator zeppelin pull ZEPPELIN Force IE to use edge compatible mode https issues apache org jira browse ZEPPELIN In Microsoft internal deployment compatible level of IE will be set to for interant sites due to group policy set by admin Then some JavaScript will be broken and home page of Zeppelin cannot be rendered We need to set X UA Compatible tag for IE to edge to force it use the latest IE version You can merge this pull request into a Git repository by running git pull https github com twilightgod incubator zeppelin master Alternatively you can review and apply these changes as the patch at https github com apache incubator zeppelin pull patch To close this pull request make a commit to your master trunk branch with at least the following in the commit message This closes commit c b badafa ef eddbcb bf c a Author Rex Xiong pengx microsoft com Date T Z Force IE to use edge compatible mode "
"CB-9851" "From Slack discussion ghenry I noticed on windows platform that cdvfile resource paths don t resolve in the web view and just present a broken link for example using img ng src cdvfile localhost persistent images test jpg works perfectly on ios and android but on the windows platform building windows universal app the image show as broken links if I inspect the dom and dynamically change the path to the image to be ms appdata local images test jpg the image pops up and displays as normal" " GitHub user daserge opened a pull request https github com apache cordova plugin file pull CB Document cdvfile protocol quirk using cdvfile in the DOM is not supported on Windows Jira issue https issues apache org jira browse CB You can merge this pull request into a Git repository by running git pull https github com MSOpenTech cordova plugin file CB Alternatively you can review and apply these changes as the patch at https github com apache cordova plugin file pull patch To close this pull request make a commit to your master trunk branch with at least the following in the commit message This closes commit eccd cefdaebbb ebf e c a Author daserge v seshak microsoft com Date T Z CB Document cdvfile protocol quirk using cdvfile in the DOM is not supported on Windows "
"SLING-6349" "If an exported model class has a method like" " fixed in r I don t think the output isn t what anyone would realistically want which is a good indication that JsonIgnore should be added to the model classes "
"UIMA-4706" "uimaFIT should be using the uimaFIT ResourceManagerFactory to create resource managers However many places in the code still call UIMAFramework newDefaultResourceManager " " Must also be used when merging type systems "
"FLINK-132" "Hi residents of the Stratosphere I found it a bit difficult to get a big picture of the memory usage of Ozone so I created this small comparison graphic ozone vs yarn You can ignore yarn Can someone confirm that it looks like this on the high level memory https f cloud github com assets e e e bb dd bfca ed e png Having such high level picture in the documentation would be great with the relevant names of the configuration options added I also omitted details like default values memory manager now defaults to heap space if I read correctly from source Settings that did not work DEFAULT NEPHELE TM HEAP GB taskmanager memory size GB Network buffers GB numberBuffers KB bufferSize KB Task manager did not start not enough heap space for GB Exception in thread main java lang OutOfMemoryError Java heap space at eu stratosphere nephele services memorymanager spi DefaultMemoryManager init DefaultMemoryManager java at eu stratosphere nephele services memorymanager spi DefaultMemoryManager init DefaultMemoryManager java at eu stratosphere nephele taskmanager TaskManager init TaskManager java at eu stratosphere nephele taskmanager TaskManager main TaskManager java Settings that worked DEFAULT NEPHELE TM HEAP GB taskmanager memory size GB Network buffers GB numberBuffers KB bufferSize KB worked there is GB heap space left" " Date Tue Oct CEST Author rmetzger Yes Network Buffers are taken from the heap space as byte arrays This was changed by https github com dimalabs ozone pull makes how should this work with GB heap space I don t see any problems with your picture but you should probably ask StephanEwen You could consider renaming Rest for UDFs to Java Objects UDFs "
"ODE-797" "Running FindBugs against bpel compile finds some possible bugs I ll address the ones that look like they are bugs and others I ll leave for the determination of the committers " " findbugs bug report for bpel compiler "
"CONNECTORS-644" "If you start a job defined for a web crawler and later click the restart link it will actually never restart but end with the following Error Repeated service interruptions failure getting document version" " failure getting document version shows up in the attached log as well "
"PIVOT-898" "When using fillIcon in images it seems that images inside buttons are displayed with wrong dimension and even wrong vertical alignment but this could be due to the parent container For example run the sample svg example bxml under org apache pivot examples svg just updated both with a PNG image and the usual SVG image " " Roger do you remember something on fillIcon some time ago there should be some related fix improvement In your applications do you see this problem "
"AMBARI-19899" "null" "null"
"CAMEL-9666" "fault property should be copied in the following places https github com apache camel blob master camel core src main java org apache camel impl DefaultExchange java L https github com apache camel blob master camel core src main java org apache camel impl DefaultExchange java L " " I am working on fix "
"TUSCANY-2860" "Multiple threads running through composite activation can cause concurrent modification like so java util ConcurrentModificationException at java util AbstractList SimpleListIterator next AbstractList java at org apache tuscany sca core assembly CompositeActivatorImpl addImplementationProvider CompositeActivatorImpl java at org apache tuscany sca core assembly CompositeActivatorImpl activate CompositeActivatorImpl java " " Let me try to describe my understanding The Tuscany code is shared in the same JVM Multiple composites are started in parallel like the concurrent starting of JEE apps The activation of the st composite triggers the lazy loading of the provider factories and the loaded flag is still false The activation of the nd composite races again which causes the ConcurrentModification issue we just have to synchronize the loadProviders method and the internal List Map can leave as is "
"AIRAVATA-1284" "null" "null"
"HBASE-15585" "While you can do all kinds of things with coprocessors like arbitrarily discard memstore data or replace files randomly during compaction I believe the ultimate power and flexibility is not there The patch aims to address this shortcoming " " Enis Soztutar stack can you guys please review "
"SPARK-18400" "Occasionally we see an NPE when we reshard our streams " " Looks like an easy fix do you want to try it the shardId in KinesisRecordProcessor could be null I suppose if shutdown happens before initalize completes or is called for some reason "
"FLUME-1499" "null" "null"
"TUSCANY-776" "I don t currently see anything that will create an HTTP sessions for components requiring session support " " fixed "
"CONFIGURATION-329" "PropertiesConfiguration does not auto save the properties file under the following circumstances File before key test PropertiesConfiguration conf new PropertiesConfiguration conf load new File test properties conf setAutoSave true System out println Conf Before changing value conf getProperty key conf setProperty key test after System out println Conf After changing value conf getProperty key File after key test " " Actually load File doesn t change the source of the configuration you have to call setFile and then load to enable the auto save feature "
"AMBARI-20308" "STR Deployed cluster with Ambari version and HDP version wire encrypted cluster Upgrade Ambari to and then start EU to Observed following failure at Atlas service check" " I believe this is because the version of curl on these system do not support TLS v cURL without TLS nats kbjs erm tofndwngdsec s tmp curl curl k tlsv w http code https curl option tlsv is unknown curl try curl help or curl manual for more information nats kbjs erm tofndwngdsec s tmp curl curl version curl x suse linux gnu libcurl OpenSSL j zlib libidn Protocols tftp ftp telnet dict ldap ldaps http file https ftps Features GSS Negotiate IDN IPv Largefile NTLM SSL libz nats kbjs erm tofndwngdsec s tmp curl curl k w http code https curl Unknown SSL protocol error in connection to cURL with TLS dev ambari vagrant centos master curl version curl x apple darwin libcurl SecureTransport zlib Protocols dict file ftp ftps gopher http https imap imaps ldap ldaps pop pop s rtsp smb smbs smtp smtps telnet tftp Features AsynchDNS IPv Largefile GSS API Kerberos SPNEGO NTLM NTLM WB SSL libz UnixSockets dev ambari vagrant centos master curl k tlsv w http code https In ATLAS TLSv was added as the default protocol and TLSv TLSv were excluded "
"SYNAPSE-1066" " Create a proxy Place it in synapse SNAPSHOT repository conf synapse config proxy services Start the server " " Vanjikumaran Sivajothy You are missing the synapse namespace in the configuration Please add the following to the root XML tag as an attribute xmlns http ws apache org ns synapse "
"PIG-1235" "Here is the script that throws this exception Pig Stack Trace ERROR Error while fixing projections No mapping available in old predecessor to replace column " " This is not relevant with new optimizer "
"COMPRESS-379" "This issue was originally reported in MASSEMBLY but it seems the root cause in inside Commons Compress Consider the attached invalid entry jar whose contents as shown by the zipinfo utility is There are some JAR files created by the Maven Assembly Plugin with content similar to this and the entry META INF maven has permissions octal Constructing a ZipFile from this file the method isUnixSymlink incorrectly returns true for the entry META INF maven and it correctly returns false for the entry META INF Here is a sample Java code that can be used to see the behaviour This code outputs The rwsrwsrwt permissions show that the Zip entry is broken in the first place but I think isUnixSymlink should still return false in that case and not consider this entry to be a symlink " " But the same would be true for all other things you do with the unix mode The flag that indicates a symlink is set in your example If we follow the logic that an attribute of all bits set is invalid then we shouldn t change the code here but getUnixMode instead so that it returns rather than SHORT MASK which in turn would remove all permissions as well Why would we trust those more than the symlink flag "
"TEZ-3284" "This is a known performance issue as documented in HADOOP Both ByteArrayOutputStream write and DataOutputStream write have lock prefix calls in them because they are object synchronized methods " " UnorderedOutSpiller Reducer RUNNABLE org apache hadoop io compress CompressorStream write int CompressorStream java org apache hadoop fs FSDataOutputStream PositionCache write int FSDataOutputStream java java io DataOutputStream writeByte int DataOutputStream java org apache hadoop io WritableUtils writeVLong DataOutput long WritableUtils java org apache hadoop io WritableUtils writeVInt DataOutput int WritableUtils java org apache tez runtime library common sort impl IFile Writer writeKVPair byte int int byte int int IFile java org apache tez runtime library common sort impl IFile Writer append DataInputBuffer DataInputBuffer IFile java org apache tez runtime library common writers UnorderedPartitionedKVWriter writePartition int UnorderedPartitionedKVWriter WrappedBuffer IFile Writer DataInputBuffer DataInputBuffer UnorderedPartitionedKVWriter java org apache tez runtime library common writers UnorderedPartitionedKVWriter access UnorderedPartitionedKVWriter int UnorderedPartitionedKVWriter WrappedBuffer IFile Writer DataInputBuffer DataInputBuffer UnorderedPartitionedKVWriter java org apache tez runtime library common writers UnorderedPartitionedKVWriter SpillCallable callInternal UnorderedPartitionedKVWriter java org apache tez runtime library common writers UnorderedPartitionedKVWriter SpillCallable callInternal UnorderedPartitionedKVWriter java org apache tez common CallableWithNdc call CallableWithNdc java java util concurrent FutureTask run FutureTask java java util concurrent ThreadPoolExecutor runWorker ThreadPoolExecutor Worker ThreadPoolExecutor java java util concurrent ThreadPoolExecutor Worker run ThreadPoolExecutor java java lang Thread run Thread java "
"TAJO-1179" "See the q a at http stackoverflow com questions how to work around travis cis mb output limit TravisCI has a limitation of log size If the log size exceeds MB or some threshold line number the test is terminated by TravisCI as failure " " GitHub user hyunsik opened a pull request https github com apache tajo pull TAJO Integration tests in TravisCI are occasionally failed due to log size You can merge this pull request into a Git repository by running git pull https github com hyunsik tajo TAJO Alternatively you can review and apply these changes as the patch at https github com apache tajo pull patch To close this pull request make a commit to your master trunk branch with at least the following in the commit message This closes commit bdc f beb a ac d a Author Hyunsik Choi hyunsik apache org Date T Z TAJO Integration tests in TravisCI are occasionally failed due to log size "
"KARAF-3793" "null" "null"
"FC-38" "There are some classes where we protect a field with a synchronized in order to avoid concurrent modifications That s ok except that one should not access the field while it s being updated There are a few cases where it s done and this should be fixed The way to do it is to use ReentrantReadWriteLock for that it allows concurrent reads unless a write lock is taken Writes will block other writes and all the reads until it s done The OrgUnitP and PolicyP are protecting sets while updating it that aren t protected when read this is fixed for OrgUnitP " " My first fix so called is not correct One can t acquire a write lock when a read lock is already hold by the thread I m trying to find a solution that actually works "
"SQOOP-746" "I believe that we should run mapreduce job with disabled speculative execution as it might cause undesirable high load on external resources " " Committed Thanks Jarcec "
"FLUME-1119" "Remove defaults for syslog sources since flume will need to run as superuser to connect to these or will need specific workarounds " " This is an automatically generated e mail To reply visit https reviews apache org r Review request for Flume Summary Remove default ports for syslog sources This addresses bug FLUME https issues apache org jira browse FLUME Diffs flume ng core src main java org apache flume source SyslogUDPSource java c ee flume ng core src main java org apache flume source SyslogTcpSource java a e b Diff https reviews apache org r diff Testing Thanks Hari "
"SPARK-20080" "Step to reproduce Use SPak Streaming application inside foreachRDD of any DStream use rdd foreachPartition use org slf j Logger Init it or use as a filed with closure inside foreachPartition action Result No exception throw foreachPartition action not executed Expected result Throw java io NotSerializableExceptiondescription When i try use or init org slf j Logger inside foreachPartition that extracted to trait method What was called in foreachRDD I have found that foreachPartition method do not execute and no exception appeared Tested on local and yarn mode spark code can be found on github There are two main class that explain problem if i will run same code with batch job I will get exception " " There is no detail here about the cause of the problem This is a normal exception It means your task isn t serializable because you re reference a Logger "
"BIGTOP-2028" "null" "null"
"DRILL-1519" "WorkEventBus uses a ConcurrentHashMap to ensure there is one and only one FragmentManager corresponding to each unique FragmentHandle The method creates a FragmentManager that reserves some initial memory if a thread observes that it is not in the map However in case of concurrent access we still need to clean up after if multiple threads observe that FragmentManager does not exist and create multiple FragmentManagers " " I noticed the same issue while looking into why the fragment memory limit implementation was over estimating the number of running fragments I have a patch ready and will send it out for review See DRILL "
"ARIES-1634" "When the BlueprintContainer is destroy it is not unregistered from the OSGi registry hence is retained in the memory But when the BlueprintContainer is quiesce it is correctly unregistered from the OSGi registry " " GitHub user adetalhouet opened a pull request https github com apache aries pull ARIES BlueprintContainer are leaked when destroyed While destroying the BlueprintContainer the associated ServiceRegistration isn t unregistered although it should be to completely release the BlueprintContainer The quiesce method does that correctly so current workaround is to first quiesce the bundle then destroy it But it feels like an oversight in the destroy method Signed off by Alexis de Talhou t adetalhouet inocybe com You can merge this pull request into a Git repository by running git pull https github com adetalhouet aries blueprint container leak Alternatively you can review and apply these changes as the patch at https github com apache aries pull patch To close this pull request make a commit to your master trunk branch with at least the following in the commit message This closes commit e ca ab c b c b e db Author Alexis de Talhou t adetalhouet inocybe com Date T Z ARIES BlueprintContainer are leaked when destroyed While destroying the BlueprintContainer the associated ServiceRegistration isn t unregistered although it should be to completely release the BlueprintContainer The quiesce method does that correctly so current workaround is to first quiesce the bundle then destroy it But it feels like an oversight in the destroy method Signed off by Alexis de Talhou t adetalhouet inocybe com "
"METAMODEL-151" "When I try to create a table with a column of type ColumnType double MetaModel throws an exception as below " " GitHub user drexler opened a pull request https github com apache metamodel pull Translate type DOUBLE to postgresql type double precision Jira Fix for METAMODEL You can merge this pull request into a Git repository by running git pull https github com drexler metamodel master Alternatively you can review and apply these changes as the patch at https github com apache metamodel pull patch To close this pull request make a commit to your master trunk branch with at least the following in the commit message This closes commit b c bae b f f e c a e b Author hdrexler github klaan nl Date T Z Translate type DOUBLE to postgresql type double precision Fixes JIRA METAMODEL "
"XALANJ-2081" "Given following stylesheet and input document Xalan Interpretive and XSLTC has difference in output Example Stylesheet xml version xsl stylesheet xmlns xsl http www w org XSL Transform version xsl output method xml version encoding UTF xsl template match out out xsl template xsl stylesheet Input XML xml version doc Output using Xalan Interpretive xml version encoding UTF out out Output using XSLTC xml version encoding UTF out Here Xalan Interpretive has correct ouptut Here x is a backspace character XSLTC treats both characters as whitespace characters Just look at following snippet of java code System out println Character isWhitespace char x System out println Character isWhitespace char x f String s u u f System out println s trim length The output for this code snippet is false true The length here should not be This shows that x is not a whitespace character but trim method of java lang String treats it as a whitespace character I believe the problem lies in the class org apache xalan xsltc compiler TextThe following line of code is the probematic if text trim length ignore true In above sample it can be seen that trim method is problematic I will attach a patch to fix this problem " " Here is the patch to resolve this issue "
"FALCON-2067" " allAttempts is expected to show all attempts corresponding to an instance rerun Although this is not the case This is happening because we are using coordinator action id instead of workflow id in instance status response as part of FALCON " " GitHub user pallavi rao opened a pull request https github com apache falcon pull FALCON In instance status list allAttempts does not show all runs After the fix bin falcon instance status type process name oozie mr process start T Z allAttempts Consolidated Status SUCCEEDED Instances Instance Cluster SourceCluster Status Start End Details Log T Z local KILLED T Z T Z http localhost oozie job oozie oozi C actions user action ERROR null T Z local KILLED T Z T Z http localhost oozie job oozie oozi C actions user action ERROR null failed post processing KILLED http localhost proxy application T Z local KILLED T Z T Z http localhost oozie job oozie oozi C actions user action ERROR null failed post processing KILLED http localhost proxy application T Z local KILLED T Z local KILLED T Z local KILLED T Z local KILLED T Z local KILLED T Z local KILLED T Z local KILLED You can merge this pull request into a Git repository by running git pull https github com pallavi rao falcon Alternatively you can review and apply these changes as the patch at https github com apache falcon pull patch To close this pull request make a commit to your master trunk branch with at least the following in the commit message This closes commit aa e f ac a a df a dae Author Pallavi Rao pallavi rao inmobi com Date T Z FALCON In instance status list allAttempts does not show all runs "
"SM-2439" "Starting a session to an SMS C with jsmpp fails with a java lang NoSuchMethodError The patch applied to jsmpp for SMX has changed the signature of the method fireStateChanged " " Patch "
"SPARK-18315" "After upgrading to in the spark solr library creating a table with Parquet format fails These statements used to run successfully in xFull stacktrace It happens with the JDBC datasource tooSimilar to JDBCRelation SolrRelation also extends the BaseRelation and InsertableRelationI am wondering if there is something that needs to be implemented for classes that extend BaseRelation and InsertableRelation" " Using the Spark SQL syntax is a good workaround for this issue CREATE TABLE test stored USING PARQUET AS SELECT FROM test instead of CREATE TABLE test stored STORED AS PARQUET LOCATION Users kiran spark test parquet AS SELECT FROM test Shouldn t the Hive SQL syntax still work "
"AMBARI-19742" "Login to user create workspace by creating a workflow logout login to user the workspace of user is restored " " Committed to branch and trunk "
"SLING-2428" "I m using JcrInstaller to generate config instances for a ManagedServiceFactory These configurations get a generated service pid and no properties indicating that this was generated via jcr node Per the docs at http sling apache org site jcr installer jcrjcrinstall and osgiinstaller html I was looking for this A node named like o a s foo bar a uses o a s foo bar as its factory PID creating a configuration with an automatically generated PID The value of a is stored as an alias property in the configuration to correlate the configuration object with the repository node demonstrate that I think that either or both should work A few noticable problems If there is another way to correlate a ManagedServiceFactory config instances with jcr installer sling OsgiConfig nodes please let me know " " specifying the node name as factory PID somename should create a config with pid factory PID somename No because the Configuration Admin specification prescribes that the PID of a factory configuration is generated by the Configuration Admin implementation and cannot be influenced So there is no way of doing something like this OR the config with generated PID should include a property like installation hint to indicate the location of the config node We had that because we needed that for the implementation of the Installer But AFAICT the OSGi Installer now uses a different mechanism to keep track of configuration nodes are there Configuration objects and so we don t need this information any longer What is your requirement to be able to correlate a Configuration object to a repository node may also be a filesystem file btw "
"LUCENE-7138" "I randomly hit this test failure " " The bug is related to coord fails for me like this but only with ClassicSimilarity expected but was "
"SM-317" "activeio jar is missing from chirinos M distribution I downloaded http people apache org chirino incubator servicemix M distributions servicemix M tar gz unpacked it and started servicemix just ran bin servicemix Start up failed with java lang NoClassDefFoundError org activeio journal Journal Downloaded activeio jar put it lib and it now starts up properly " " Resolved by Hiram Chirino "
"BIGTOP-1526" "The following line in FailureVars class" " Instead of a location being hard coded for propertyFile it will now be set in the command line for the parameter failurePropertiesFile "
"GIRAPH-39" "mvn verify fails for me due to the existence of git and idea IntelliJ Idea s tracking folder It fails all the files within those directories " " Patch to add git and idea to rat s exclude list With this patch mvn verify succeeds "
"FLINK-3188" "When keys are deleted in the kafka queue they show up as keys with null payload Currently in Flink SNAPSHOT these deletions are silently skipped without increasing current offset This leads to two problems When a fetch window contains only deletions LegacyFetcher gets stuck For KeyedDeserializationSchemas it would make sense to pass deletions to the deserializer so that it can decide to wrap deleted keys as a deletion command This is also more consistent with the semantics of keys in Kafka queues When compaction is activated only the latest message with the same key needs to be kept by Kafka " " Patch to LegacyFetcher to pass deletions on to DeserializationSchema "
"CB-11676" "this is a open source project on Github https github com siddmegadeth cordova file scannerhe goal is to provide a set of API to traverse search any kind of file on ANdroid system based on file type The File Plugin API returnsfileError Code This is not replicated on on ZenfoneMoto G Turbo marshmallow Does not work Asus Zenfine Android Works as expectedAPI USAGE var url cordova file dataDirectory cordova file documentsDirectory cordova file externalApplicationStorageDirectory cordova file externalCacheDirectory cordova file externalRootDirectory cordova file sharedDirectory cordova file syncedDataDirectory cordova file applicationStorageDirectory cordova file cacheDirectory cordova file applicationDirectory cordova file tempDirectory cordova file rootDirectory fileType mp mp avi pdf cordovaFile scan url fileType function resp function error API DETAIL DESCRIPTIONvar file angular module CordovaFileReader file service cordovaFile function q timeout var list var deferred q defer var promises deferred promise return scan function url fileType success failure var i while i fileType length list fileType list fileType Get List Of FilesType and Create named associativr Array Function Definition For fileEntry and Error var fileSearch function entry var dirReader entry createReader dirReader readEntries function entries var i while i entries length if entries i isDirectory true else var j while j fileType length if entries i name indexOf fileType j var file file entries i file type fileType j list fileType j push file j if entries i name indexOf fileType var file file entries i file type fileType list fileType push file promises push file console log file else if entries i name indexOf fileType var file file entries i file type fileType list fileType push file console log file promises push file i Return List As CurrentSearch File and ll Files Searched in globalLis deferred resolve success list function error return q all promises Func ENds var i while i url length if url i nul" " Thoughts Why are you wrapping cordova file dataDirectory in quotes I wouldn t ever expect that to work with the file plugin s URI resolution methods Pass it without quotes and see if the behavior improves Please post a link to a sample app that duplicates the failures you are seeing so we can easily duplicate the issue Please verify which version s of the File Plugin you are using If you aren t using the latest try upgrading to see if that helps Please verify which version s of cordova android you are using If you aren t using the latest try upgrading to see if that helps "
"HADOOP-12999" "Querying data stored in S via Hive causes a NPE The exception occurs when Hive Metastore uses hadoop aws tools to query the bucket structure in S Example Hive query The required bucket folder exists properly in S Also there is a folder entry on the same directory level which is an often used workaround for S tools that cannot handle empty folders The following is an excerpt of the stack trace in Hive console log After digging into the code it appears that the root cause for this issue is not in Hive but in the way that hadoop aws is querying the bucket information from S We have verified that the Path parameter passed into org apache hadoop hive common FileUtils mkdir is indeed NOT null " " the original s fs is deprecated to the extent of probably being cut from hadoop data natively stored via s n s a being the way modern applications work with the storage are you really trying to work with s data or is this a regression test "
"FALCON-1880" "when using Distcp to copy the file from one Encyption to another Encryption and it is failing with the following error " " GitHub user bvellanki opened a pull request https github com apache falcon pull FALCON Support TDE encryption Add skipcrccheck to distcp options for HiveDR You can merge this pull request into a Git repository by running git pull https github com bvellanki falcon master Alternatively you can review and apply these changes as the patch at https github com apache falcon pull patch To close this pull request make a commit to your master trunk branch with at least the following in the commit message This closes commit db cf ebf bed fa f cd a e Author bvellanki bvellanki hortonworks com Date T Z FALCON To support TDE encryption Add skipcrccheck to distcp options for HiveDR "
